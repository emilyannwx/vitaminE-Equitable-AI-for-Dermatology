{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90489,"databundleVersionId":10898385,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task: Transfer Learning part :) ","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Set paths to directories\nTRAIN_DIR = '/kaggle/input/bttai-ajl-2025/train/train'\nTEST_DIR = '/kaggle/input/bttai-ajl-2025/test/test'\nTEST_CSV_PATH = '/kaggle/input/bttai-ajl-2025/test.csv'  # test metadata\n\n# Image and training parameters\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T04:27:12.131148Z","iopub.execute_input":"2025-03-15T04:27:12.131560Z","iopub.status.idle":"2025-03-15T04:27:29.257120Z","shell.execute_reply.started":"2025-03-15T04:27:12.131528Z","shell.execute_reply":"2025-03-15T04:27:29.255826Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Data Augmentation & Generators for Training and Validation","metadata":{}},{"cell_type":"code","source":"# Use ImageDataGenerator with a validation split (20%)\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    validation_split=0.2,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    zoom_range=0.2\n)\n\n# Training generator: loads images from subdirectories (each subdirectory is a class)\ntrain_generator = train_datagen.flow_from_directory(\n    directory=TRAIN_DIR,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    subset='training',\n    class_mode='categorical',\n    shuffle=True\n)\n\n# Validation generator\nval_generator = train_datagen.flow_from_directory(\n    directory=TRAIN_DIR,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    subset='validation',\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T04:27:29.258471Z","iopub.execute_input":"2025-03-15T04:27:29.259265Z","iopub.status.idle":"2025-03-15T04:27:29.661475Z","shell.execute_reply.started":"2025-03-15T04:27:29.259190Z","shell.execute_reply":"2025-03-15T04:27:29.660489Z"}},"outputs":[{"name":"stdout","text":"Found 2300 images belonging to 21 classes.\nFound 560 images belonging to 21 classes.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Build Model with Transfer Learning using EfficientNetB0","metadata":{}},{"cell_type":"code","source":"# Load pre-trained EfficientNetB0 (without the top layers)\nbase_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\nbase_model.trainable = False  # Freeze base model for initial training\n\n# Add custom layers on top\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.3)(x)\nnum_classes = train_generator.num_classes  # Automatically detects the number of classes\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# Construct the full model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Callbacks for early stopping and learning rate reduction\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T04:27:29.662615Z","iopub.execute_input":"2025-03-15T04:27:29.662877Z","iopub.status.idle":"2025-03-15T04:27:31.467711Z","shell.execute_reply.started":"2025-03-15T04:27:29.662856Z","shell.execute_reply":"2025-03-15T04:27:31.466541Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=15,  # Adjust as needed\n    callbacks=[early_stop, reduce_lr]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T04:27:31.469956Z","iopub.execute_input":"2025-03-15T04:27:31.470374Z","iopub.status.idle":"2025-03-15T05:09:10.607049Z","shell.execute_reply.started":"2025-03-15T04:27:31.470343Z","shell.execute_reply":"2025-03-15T05:09:10.605759Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.1419 - loss: 2.8550 - val_accuracy: 0.2732 - val_loss: 2.4146 - learning_rate: 0.0010\nEpoch 2/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.3122 - loss: 2.2380 - val_accuracy: 0.3214 - val_loss: 2.1965 - learning_rate: 0.0010\nEpoch 3/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.3852 - loss: 2.0078 - val_accuracy: 0.3500 - val_loss: 2.1042 - learning_rate: 0.0010\nEpoch 4/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.4257 - loss: 1.9025 - val_accuracy: 0.3768 - val_loss: 2.0264 - learning_rate: 0.0010\nEpoch 5/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.4492 - loss: 1.7967 - val_accuracy: 0.3857 - val_loss: 1.9623 - learning_rate: 0.0010\nEpoch 6/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.4707 - loss: 1.7184 - val_accuracy: 0.4143 - val_loss: 1.9183 - learning_rate: 0.0010\nEpoch 7/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.4653 - loss: 1.7245 - val_accuracy: 0.3893 - val_loss: 1.9205 - learning_rate: 0.0010\nEpoch 8/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.4944 - loss: 1.6356 - val_accuracy: 0.4196 - val_loss: 1.8644 - learning_rate: 0.0010\nEpoch 9/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5155 - loss: 1.5923 - val_accuracy: 0.4339 - val_loss: 1.8849 - learning_rate: 0.0010\nEpoch 10/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.5457 - loss: 1.4945 - val_accuracy: 0.4036 - val_loss: 1.8477 - learning_rate: 0.0010\nEpoch 11/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5486 - loss: 1.4929 - val_accuracy: 0.4196 - val_loss: 1.8401 - learning_rate: 0.0010\nEpoch 12/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5419 - loss: 1.4732 - val_accuracy: 0.4268 - val_loss: 1.8165 - learning_rate: 0.0010\nEpoch 13/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5248 - loss: 1.4772 - val_accuracy: 0.4482 - val_loss: 1.8000 - learning_rate: 0.0010\nEpoch 14/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.5463 - loss: 1.4218 - val_accuracy: 0.4732 - val_loss: 1.7684 - learning_rate: 0.0010\nEpoch 15/15\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5768 - loss: 1.3747 - val_accuracy: 0.4714 - val_loss: 1.7402 - learning_rate: 0.0010\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# F1 Score Calculations","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n# Calculate F1 score on the validation set\nval_steps = val_generator.n // val_generator.batch_size + 1\ny_true = val_generator.classes\n\n# Generate predictions on the validation data\nval_preds_probs = model.predict(val_generator, steps=val_steps, verbose=1)\ny_pred = np.argmax(val_preds_probs, axis=1)\n\n# Compute the weighted F1 score\nf1 = f1_score(y_true, y_pred, average='weighted')\nprint(\"Weighted F1 Score on Validation Set:\", f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:09:10.612376Z","iopub.execute_input":"2025-03-15T05:09:10.612779Z","iopub.status.idle":"2025-03-15T05:09:45.277749Z","shell.execute_reply.started":"2025-03-15T05:09:10.612742Z","shell.execute_reply":"2025-03-15T05:09:45.276392Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step\nWeighted F1 Score on Validation Set: 0.4323484110719362\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Generate Predictions on the Test Set and Create Submission File","metadata":{}},{"cell_type":"code","source":"# Using test.csv to map file names for the test set\nif os.path.exists(TEST_CSV_PATH):\n    test_df = pd.read_csv(TEST_CSV_PATH)\n    # Build full file paths by appending the .jpg extension to each md5hash\n    test_df['filepath'] = TEST_DIR + '/' + test_df['md5hash'] + '.jpg'\n    \n    # Create a test generator from the dataframe\n    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n    test_generator = test_datagen.flow_from_dataframe(\n        dataframe=test_df,\n        x_col='filepath',\n        y_col=None,\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        class_mode=None\n    )\n    \n    # Predict probabilities for test images\n    preds = model.predict(test_generator, verbose=1)\n    predicted_class_indices = np.argmax(preds, axis=1)\n    \n    # Map indices back to class labels using the training generator mapping\n    labels_map = {v: k for k, v in train_generator.class_indices.items()}\n    predicted_labels = [labels_map[idx] for idx in predicted_class_indices]\n    \n    # Add predictions to the dataframe and create submission file\n    test_df['label'] = predicted_labels\n    submission = test_df[['md5hash', 'label']]\n    submission.to_csv('submission.csv', index=False)\n    print(\"Submission file created and saved as submission.csv\")\nelse:\n    print(\"test.csv not found. Skipping test set predictions.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:09:45.279008Z","iopub.execute_input":"2025-03-15T05:09:45.279916Z","iopub.status.idle":"2025-03-15T05:10:52.743903Z","shell.execute_reply.started":"2025-03-15T05:09:45.279872Z","shell.execute_reply":"2025-03-15T05:10:52.742515Z"}},"outputs":[{"name":"stdout","text":"Found 1227 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step\nSubmission file created and saved as submission.csv\n","output_type":"stream"}],"execution_count":6}]}